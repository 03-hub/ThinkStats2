{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SemEvaltask1-submission-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPib54giK0whkFiTukTqds8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/03-hub/ThinkStats2/blob/master/Copy_of_SemEvaltask1_submission_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTING CONTRIBUTION SENTENCES USING LSTM MODEL"
      ],
      "metadata": {
        "id": "A8FoUyLcuEef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qc-REv0xpC_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cr8dvvu41XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0da5b04-7e08-409f-f762-5df382c49e4d",
        "cellView": "code"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)  \n",
        "#(function) mount: (mountpoint, force_remount=False, timeout_ms=120000) -> None\n",
        "\n",
        "#Mount your Google Drive at the specified mountpoint path."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ncg-task/training-data.git \"/content/train\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnQgGSKUPYZS",
        "outputId": "8da8ee52-566e-47c0-928e-9a255801d375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/train'...\n",
            "remote: Enumerating objects: 6864, done.\u001b[K\n",
            "remote: Counting objects: 100% (3083/3083), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2728/2728), done.\u001b[K\n",
            "remote: Total 6864 (delta 567), reused 2504 (delta 279), pack-reused 3781\u001b[K\n",
            "Receiving objects: 100% (6864/6864), 157.36 MiB | 29.42 MiB/s, done.\n",
            "Resolving deltas: 100% (660/660), done.\n",
            "Checking out files: 100% (3286/3286), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING REQUIRED LIBRARIES"
      ],
      "metadata": {
        "id": "hb0J2g_a8BnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install transformers\n",
        "from transformers import BertConfig, BertTokenizerFast, TFBertForSequenceClassification\n",
        "EPOCHS = 3#I choosed 3 epochs i.e;my training dataset passes through lstm model 3 times\n",
        "BATCH_SIZE = 8#I use 8 training examples in one iteration\n"
      ],
      "metadata": {
        "id": "B4IYgBi-8BzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf839be-ae57-447c-9ad9-ad6e1fa2ec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 85.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Articlesandcontributions(path):\n",
        "    articles = []\n",
        "    contributions = []\n",
        "\n",
        "    for task_name in os.listdir(path):  #/training-data\n",
        "        if task_name != 'README.md' and task_name != '.git':\n",
        "          article_category = os.path.join(path, task_name)  # ./training-data/natural_language_inference\n",
        "\n",
        "          for folder_name in sorted(os.listdir(article_category)):\n",
        "            #os.listdir(path=None)\n",
        "\n",
        "#             Return a list containing the names of the files in the directory.\n",
        "\n",
        "#             path can be specified as either str, bytes, or a path-like object.  If path is bytes,\n",
        "#             the filenames returned will also be bytes; in all other circumstances\n",
        "#             the filenames returned will be str.\n",
        "#             If path is None, uses the path='.'.\n",
        "              article_index = os.path.join(article_category, folder_name)  # ./datasets/training-data/natural_language_inference/0\n",
        "#             os.path.join(a,*p)\n",
        "\n",
        "#              Join two or more pathname components, inserting '/' as needed.\n",
        "#              If any component is an absolute path, all previous path components\n",
        "#              will be discarded.  An empty last part will result in a path that\n",
        "#              ends with a separator.\n",
        "              with open(glob.glob(os.path.join(article_index, '*-Stanza-out.txt'))[0], encoding='utf-8') as f:#I used glob to retrieve files with matching pattern\n",
        "                  article = f.read()                                                                           #* wild card matches the files with stanze out.txt\n",
        "                  articles.append(article.lower())\n",
        "                \n",
        "              with open(os.path.join(article_index, 'sentences.txt'), encoding='utf-8') as f:\n",
        "                  contribution = []\n",
        "                  for line in f.readlines():\n",
        "                      article_contribution = int(line.strip())\n",
        "                      contribution.append(article_contribution)\n",
        "                  contributions.append(contribution) #contribution=[99,10.....]\n",
        "          #     break\n",
        "          # break\n",
        "    return articles, contributions"
      ],
      "metadata": {
        "id": "qKWkjRvL-Xjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SentenceAndLables(articles, contributions):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for i, article in enumerate(articles):\n",
        "#enumerate(*args, **kwargs)\n",
        "\n",
        "# Return an enumerate object.\n",
        "\n",
        "# iterable\n",
        "#   an object supporting iteration\n",
        "\n",
        "#The enumerate object yields pairs containing a count (from start, which\n",
        "#defaults to zero) and a value yielded by the iterable argument.\n",
        "\n",
        "#enumerate is useful for obtaining an indexed list:\n",
        "#   (0, seq[0]), (1, seq[1]), (2, seq[2]), ...\n",
        "\n",
        "        contribution = contributions[i]\n",
        "\n",
        "        sents = article.split('\\n')[0:-1]\n",
        "\n",
        "        for j, sent in enumerate(sents):\n",
        "            sentences.append(sent)\n",
        "            if (j + 1) in contribution:\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(0)\n",
        "    return sentences, labels\n"
      ],
      "metadata": {
        "id": "4Mg55w3RJCC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_dir='/content/train'"
      ],
      "metadata": {
        "id": "KjA_qJexQ_vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_articles, train_contributions = Articlesandcontributions(train_input_dir)\n",
        "\n",
        "train_sentences, train_labels = SentenceAndLables(train_articles, train_contributions)\n",
        "\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(train_sentences, train_labels, test_size=.2)\n",
        "#def train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
        "\n",
        "#Split arrays or matrices into random train and test subsets.\n",
        "\n",
        "#list: train_sentences\n",
        "#(44160 items) ['experiments show an ...', 'this assumption may.]\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "5SlgejiqM2Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ZpawpM343Jpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING"
      ],
      "metadata": {
        "id": "eXH1atyfAlqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "#def __init__(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
        "\n",
        "#Text tokenization utility class.\n",
        "#This class allows to vectorize a text corpus, by turning each\n",
        "#text into either a sequence of integers (each integer being the index\n",
        "#of a token in a dictionary) or into a vector where the coefficient\n",
        "#for each token could be binary, based on word count, based on tf-idf..\n",
        "\n",
        "tok.fit_on_texts(train_sentences)\n",
        "#(method) fit_on_texts: (texts) -> None\n",
        "#Updates internal vocabulary based on a list of texts.\n",
        "\n",
        "sequences = tok.texts_to_sequences(train_sentences)\n",
        "#(method) texts_to_sequences: (texts) -> list[list]\n",
        "#Transforms each text in texts to a sequence of integers.\n",
        "#Only top num_words-1 most frequent words will be taken into account.\n",
        "#Only words known by the tokenizer will be taken into account.\n",
        "\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "#def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
        "#Pads sequences to the same length.\n",
        "#This function transforms a list (of length num_samples)\n",
        "#of sequences (lists of integers)\n",
        "#into a 2D Numpy array of shape (num_samples, num_timesteps).\n",
        "#num_timesteps is either the maxlen argument if provided,\n",
        "#or the length of the longest sequence in the list.\n",
        "\n",
        "\n",
        "tok.fit_on_texts(test_sentences)\n",
        "\n",
        "t_sequences = tok.texts_to_sequences(test_sentences)\n",
        "\n",
        "t_sequences_matrix = sequence.pad_sequences(t_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "sNtwX1FN7CLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING MODEL"
      ],
      "metadata": {
        "id": "Bs7R0sQ_AckI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    #def __init__(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
        "\n",
        "    #Turns positive integers (indexes) into dense vectors of fixed size.\n",
        "    #e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
        "\n",
        "    layer = LSTM(64)(layer)\n",
        "    #def __init__(units, activation='tanh', recurrent_activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
        "    #return_sequences=False, return_state=False, go_backwards=False, stateful=False, time_major=False, unroll=False, **kwargs)\n",
        "    #LSTM(64) reduces the feature size to 64.Since,return_sequences=False,it outputs a feature vector of size 1*64\n",
        "\n",
        "    layer = Dense(256)(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    #def __init__(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
        "\n",
        "    #Dense implements the operation:\n",
        "    #output = activation(dot(input, kernel) + bias)\n",
        "    #where activation is the element-wise activation function\n",
        "    #passed as the activation argument\n",
        "\n",
        "    layer = Dense(128)(layer)\n",
        "    layer=Activation('relu')(layer)\n",
        "\n",
        "    layer = Dropout(0.1)(layer)\n",
        "    #def def __init__(rate, noise_shape=None, seed=None, **kwargs)\n",
        "    #Applies Dropout to the input.\n",
        "    #The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 \n",
        "    #are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
        "\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    #Model groups layers into an object with training and inference features.\n",
        "    return model"
      ],
      "metadata": {
        "id": "geTgMS6iocBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=NN()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "\n",
        "#Loss function says how good our model is in prediction.\n",
        "#Binary crossentropy is the negative average of the log of corrected predicted probabilities.It compares each of the predicted probabilities to actual\n",
        "#class output which can be either 0 or 1\n",
        "\n",
        "#Adam is an algorithm for gradient based stochastic objective functions.It combines the advantages of two SGD extensions-RMSpROP and AdaGrad.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxvNlb84oPhp",
        "outputId": "2a521655-2b60-41b8-85e9-b46c6404f2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 129,105\n",
            "Trainable params: 129,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "5mrYJEFtDlzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sequences_matrix=np.array(sequences_matrix) #Converting 2D matrix to 1D array\n",
        "train_labels=np.array(train_labels)         #Converting list to 1D array\n",
        "\n",
        "history=model.fit(sequences_matrix,train_labels,batch_size=128,epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCV5m0xvaVz",
        "outputId": "ac98ba46-879f-403c-c950-6ed9d7fc7ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "345/345 [==============================] - 46s 134ms/step - loss: 0.0570 - accuracy: 0.9779\n",
            "Epoch 2/10\n",
            "345/345 [==============================] - 47s 136ms/step - loss: 0.0543 - accuracy: 0.9794\n",
            "Epoch 3/10\n",
            "345/345 [==============================] - 47s 136ms/step - loss: 0.0487 - accuracy: 0.9807\n",
            "Epoch 4/10\n",
            "345/345 [==============================] - 48s 138ms/step - loss: 0.0459 - accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "345/345 [==============================] - 46s 135ms/step - loss: 0.0453 - accuracy: 0.9829\n",
            "Epoch 6/10\n",
            "345/345 [==============================] - 45s 131ms/step - loss: 0.0435 - accuracy: 0.9838\n",
            "Epoch 7/10\n",
            "345/345 [==============================] - 45s 130ms/step - loss: 0.0374 - accuracy: 0.9861\n",
            "Epoch 8/10\n",
            "345/345 [==============================] - 45s 129ms/step - loss: 0.0365 - accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "345/345 [==============================] - 44s 128ms/step - loss: 0.0391 - accuracy: 0.9853\n",
            "Epoch 10/10\n",
            "345/345 [==============================] - 48s 140ms/step - loss: 0.0361 - accuracy: 0.9868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtqp5KQuJqiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix,accuracy_score\n",
        "\n",
        "test_matrix=np.array(t_sequences_matrix)\n",
        "test_labels=np.array(test_labels)\n",
        "test_acc = model.evaluate(test_matrix,test_labels)\n",
        "train_acc=model.evaluate(sequences_matrix,train_labels)\n",
        "\n",
        "# (method) evaluate: (x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs) -> (Any | list)\n",
        "\n",
        "#Returns the loss value & metrics values for the model in test mode.\n",
        "#Computation is done in batches (see the batch_size arg.)\n",
        "#Args:\n",
        "#   x: Input data. It could be:\n",
        "#    A Numpy array (or array-like), or a list of arrays\n",
        "#    (in case the model has multiple inputs).\n",
        "#plot loss during training\n",
        "plt.subplot(211)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'],label='train')\n",
        "plt.legend()\n",
        "\n",
        "#plot accuracy during training\n",
        "plt.subplot(212)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'],label='train')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "iXNx5hMWC4xv",
        "outputId": "f77a6793-1b37-410a-bf79-592ec430717e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "346/346 [==============================] - 7s 20ms/step - loss: 1.5828 - accuracy: 0.8482\n",
            "1380/1380 [==============================] - 28s 20ms/step - loss: 0.0263 - accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATING ON TEST MATRIX"
      ],
      "metadata": {
        "id": "MNWx4eFrbckC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs=model.predict(test_matrix,verbose=0)\n",
        "y_probs=y_probs[:,0]\n",
        "\n",
        "accuracy=accuracy_score(test_labels,y_probs.round())\n",
        "print('accuracy: %f' % accuracy)\n",
        "#(y_true, y_pred, *, beta=1, labels=None, pos_label=1, average=None, warn_for=(\"precision\", \"recall\", \"f-score\"), sample_weight=None, zero_division=\"warn\") \n",
        "#-> (tuple[float64, float64, float64, None] | tuple[Any, Any, Any, ndarray | Any | None])\n",
        "precision=precision_score(test_labels,y_probs.round())\n",
        "print('Precision: %f' % precision)\n",
        "#Compute precision, recall, F-measure and support for each class.\n",
        "\n",
        "#The precision is the ratio tp / (tp + fp) where tp is the number of\n",
        "#true positives and fp the number of false positives. The precision is\n",
        "#intuitively the ability of the classifier not to label as positive a sample\n",
        "#that is negative\n",
        "recall=recall_score(test_labels,y_probs.round())\n",
        "print('Recall; %f'%recall)\n",
        "\n",
        "f1=f1_score(test_labels,y_probs.round())\n",
        "print('F1 Score; %f' % f1)\n",
        "\n",
        "cm=confusion_matrix(test_labels,y_probs.round())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt8Zdd-PYiyl",
        "outputId": "15ca7832-77f3-435a-f7b3-fe57398ae16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.848202\n",
            "Precision: 0.122673\n",
            "Recall; 0.113475\n",
            "F1 Score; 0.117895\n",
            "[[9253  801]\n",
            " [ 875  112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wJpyQBHRuAjW"
      }
    }
  ]
}